{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhood Growth Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_43816/3378070634.py:2: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_43816/3378070634.py:3: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load all data\n",
    "raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
    "raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "\n",
    "# load the first quadrat that we will be working with\n",
    "quad1_t1 = raw_data_t1.loc[raw_data_t1['quadrat']==1]\n",
    "quad1_t2 = raw_data_t2.loc[raw_data_t2['quadrat']==1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only care about the tree IDs and DBHs of quad1_t2\n",
    "expected_labels = quad1_t2[['treeID', 'dbh']]\n",
    "expected_labels = expected_labels.rename(columns={\"dbh\": \"dbh2\", \"treeID\": \"treeID2\"})\n",
    "\n",
    "#quad1_t1.head()\n",
    "# simplify the data to have less features\n",
    "quad1_t1 = quad1_t1[['treeID', 'sp', 'gx', 'gy', 'dbh']]\n",
    "quad1_t1 = quad1_t1.rename(columns={\"dbh\": \"dbh1\", \"treeID\":\"treeID1\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= ce.BinaryEncoder(cols=['sp'],return_df=True)\n",
    "quad1_t1 = encoder.fit_transform(quad1_t1)\n",
    "df_combined = pd.concat([quad1_t1, expected_labels], axis=1)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_combined_clean = df_combined.dropna()\n",
    "\n",
    "# Now has more values because species is encoded to 7 different categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the cleaned DataFrame and labels\n",
    "df_clean = df_combined_clean[quad1_t1.columns]\n",
    "labels_clean = df_combined_clean[expected_labels.columns]\n",
    "\n",
    "quad1_t1 = df_clean.to_numpy()\n",
    "expected_labels = labels_clean.to_numpy()\n",
    "\n",
    "quad1_t1 = quad1_t1.astype(np.float32)\n",
    "expected_labels = expected_labels.astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: attempt with just one tree - will become the body of the loop below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = quad1_t1[:,0]\n",
    "x_coordinates = quad1_t1[:, 8]  \n",
    "y_coordinates = quad1_t1[:, 9]\n",
    "coord_matrix = np.column_stack((x_coordinates, y_coordinates))\n",
    "\n",
    "spatial_tree = sp.spatial.KDTree(coord_matrix)\n",
    "focal_tree_loc = coord_matrix[0]\n",
    "dist, ind = spatial_tree.query(focal_tree_loc, k=6)\n",
    "nn_ids = ids[ind]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: attempting with LOOP - works great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dist_matrix = np.zeros((len(coord_matrix),6))\n",
    "nn_ind_matrix = np.zeros((len(coord_matrix),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tree in enumerate(coord_matrix):\n",
    "    dist2, ind2 = spatial_tree.query(tree, k=6)\n",
    "    nn_ind_matrix[i] = ids[ind2]\n",
    "    nn_dist_matrix[i]= dist2\n",
    "\n",
    "# remove the columns with the focal tree's OWN distance and IDS\n",
    "nn_ind_matrix = nn_ind_matrix[:,1:]\n",
    "nn_dist_matrix = nn_dist_matrix[:,1:]\n",
    "\n",
    "  # if we wanted to just use the ids instead of the distances of the nearest \n",
    "  # neighbors (mostly just helps with making sure the algorithm is running \n",
    "  # consistently, so used during testing), we would set ..[i] = ids[ind2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: trying to increase efficiency by using numpy broadcasting isntead of loops. will get back to this later on because it adds another dimension such that the data is nx1x50 instead of nx50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist3, ind3 = tree2.query(coord_matrix, k=50)\n",
    "#ind_array = np.arange(len(coord_matrix))\n",
    "\n",
    "#nn_dist_matrix2 = dist3[ind_array[:,None],:]\n",
    "#before = ids[ind3]\n",
    "#nn_dist_matrix3 = before[ind_array[:,None],:]\n",
    "#ADDS ANOTHER DIMENSION\n",
    "#np.zeros((len(coord_matrix),50))\n",
    "#nn_dist_matrix2[ind_array] = ids[ind3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: add the focal tree's species and dbh. This model will consider the focal tree's features as well as the distances from other trees. It will NOT consider the species or DBH of those other trees yet. I am removing the raw x and y coordinates here because distance is far more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbhs = quad1_t1[:, 10]\n",
    "species = quad1_t1[:,1:8]\n",
    "features = np.column_stack([ids, dbhs])\n",
    "#print (np.shape(features))\n",
    "#print (np.shape(species))\n",
    "features = np.column_stack([features, species, nn_dist_matrix])\n",
    "#print (np.shape(features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT, use a loop to add the dbh of each tree. To do this, must add extra dimensions. Will not include species yet because it will add many more dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_w_dbh = features\n",
    "for i in range(5):\n",
    "    n = np.shape(nn_ind_matrix)[0]\n",
    "    relevant_inds = nn_ind_matrix[:,i]\n",
    "    #print (relevant_inds)\n",
    "    \n",
    "    corresp_dbhs = np.zeros(n)\n",
    "    for j in range(n):\n",
    "        index = int(relevant_inds[j])\n",
    "        row =  quad1_t1[quad1_t1[:, 0] == index][:,10]\n",
    "        # print (index)\n",
    "        # print (row)\n",
    "        corresp_dbhs[j] = row\n",
    "        #print(\"correct is\" + str(index))\n",
    "\n",
    "    feat_w_dbh = np.column_stack((feat_w_dbh, corresp_dbhs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try: is error higher or lower when adding the dbh right after the distance? alternated throughout?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data For ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the labels so that they show GROWTH, not future DBH - better for readability of loss\n",
    "expected_labels[:,1] = expected_labels[:,1] - quad1_t1[:,10]\n",
    "expected_labels = np.where (expected_labels<0, 0, expected_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_w_dbh, expected_labels, test_size=0.3)\n",
    "\n",
    "feats = X_train[:,1:]\n",
    "labels = y_train[:,1]\n",
    "\n",
    "test_ids = X_test[:,0]\n",
    "test_feats = X_test[:,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKLearn's Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.712857904106027\n",
      "-0.16286558055070288\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(feats,labels)\n",
    "\n",
    "preds = random_forest.predict(test_feats)\n",
    "preds_matrix = np.column_stack((test_ids, preds))\n",
    "\n",
    "error1 = sklearn.metrics.mean_squared_error(y_test[:,1], preds)\n",
    "print (np.sqrt(error1))\n",
    "error1a = r2_score(y_test[:,1],preds)\n",
    "print (error1a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.802576\n",
      "0.29114872161262717\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBRegressor()\n",
    "xgb_tree.fit(feats,labels)\n",
    "preds2 = xgb_tree.predict(test_feats)\n",
    "predictions_matrix = np.column_stack((test_ids, preds2))\n",
    "error2 = sklearn.metrics.mean_squared_error(y_test[:,1], preds2)\n",
    "print (np.sqrt(error2))\n",
    "error2a = r2_score (y_test[:,1], preds2)\n",
    "print (error2a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can now attempt to add species too, and then train on all of this - how does the error change when adding species? NOTE: current error with column 9 (all zeros) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_w_dbh_species = features\n",
    "for i in range(5):\n",
    "    n = np.shape(nn_ind_matrix)[0]\n",
    "    relevant_inds = nn_ind_matrix[:,i]\n",
    "    #print (relevant_inds)\n",
    "    \n",
    "    corresp_dbhs = np.zeros((n,7))\n",
    "    for j in range(n):\n",
    "        index = int(relevant_inds[j])\n",
    "        row =  quad1_t1[quad1_t1[:, 0] == index][:,2:9]\n",
    "        # print (index)\n",
    "        # print (row)\n",
    "        corresp_dbhs[j] = row\n",
    "        #print(\"correct is\" + str(index))\n",
    "\n",
    "    feat_w_dbh_species = np.hstack((feat_w_dbh_species, corresp_dbhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feat_w_dbh_species, expected_labels, test_size=0.3)\n",
    "\n",
    "feats = X_train[:,1:]\n",
    "labels = y_train[:,1]\n",
    "\n",
    "test_ids = X_test[:,0]\n",
    "test_feats = X_test[:,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKLearn's Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.690216372869145\n",
      "0.2049755215848027\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(feats,labels)\n",
    "\n",
    "preds = random_forest.predict(test_feats)\n",
    "preds_matrix = np.column_stack((test_ids, preds))\n",
    "\n",
    "error1 = sklearn.metrics.mean_squared_error(y_test[:,1], preds)\n",
    "print (np.sqrt(error1))\n",
    "error1a = r2_score(y_test[:,1],preds)\n",
    "print (error1a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.615017\n",
      "0.2102364404481949\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBRegressor()\n",
    "xgb_tree.fit(feats,labels)\n",
    "preds2 = xgb_tree.predict(test_feats)\n",
    "predictions_matrix = np.column_stack((test_ids, preds2))\n",
    "error2 = sklearn.metrics.mean_squared_error(y_test[:,1], preds2)\n",
    "print (np.sqrt(error2))\n",
    "error2a = r2_score (y_test[:,1], preds2)\n",
    "print (error2a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomization: at least as good as the model without neighbors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Oct 26 2021, 07:25:54) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ea42a2acbac2542a5ba28118d5ac45aa30cdd1086d6bdd4fc2eb17ce0fd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
