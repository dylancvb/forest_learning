{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SKLEARN DECISION TREE REGRESSOR working with 1985 to 1990 data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most basic imports that I would need, need more to visualize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, must load the data!\n",
    "t1 represents the data we are working on predicting, while t2 represents the expected values of the prediction. t2 will be used primarily\n",
    "for calculating the loss function. Switch to 85 and 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_43399/3260900854.py:2: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_43399/3260900854.py:3: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load all data\n",
    "raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
    "raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "\n",
    "# load the first quadrat that we will be working with\n",
    "quad1_t1 = raw_data_t1.loc[raw_data_t1['quadrat']==1]\n",
    "quad1_t2 = raw_data_t2.loc[raw_data_t2['quadrat']==1]\n",
    "\n",
    "# we only care about the tree IDs and DBHs of quad1_t2\n",
    "expected_labels = quad1_t2[['treeID', 'dbh']]\n",
    "expected_labels = expected_labels.rename(columns={\"dbh\": \"dbh2\", \"treeID\": \"treeID2\"})\n",
    "\n",
    "#quad1_t1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify data: extract important features. Next step: remove trees that are dead in either census, other cleaning this way to get rid of data errors. This could involve no species listed, or zero or NaN DBH. Later on, will need the actual date too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the data to have less features\n",
    "quad1_t1 = quad1_t1[['treeID', 'sp', 'gx', 'gy', 'dbh']]\n",
    "quad1_t1 = quad1_t1.rename(columns={\"dbh\": \"dbh1\", \"treeID\":\"treeID1\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all of the species present and index them in a list. \n",
    "\n",
    "NOTE: Now am exploring different ways to encode the species so that they are  ordered nominally!\n",
    "\n",
    "Probably makes sense to use hash encoding because there are so many possible options for species (just in this one quadrat, 85 species are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treeID1</th>\n",
       "      <th>sp_0</th>\n",
       "      <th>sp_1</th>\n",
       "      <th>sp_2</th>\n",
       "      <th>sp_3</th>\n",
       "      <th>sp_4</th>\n",
       "      <th>sp_5</th>\n",
       "      <th>sp_6</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>dbh1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8223</th>\n",
       "      <td>8224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230867</th>\n",
       "      <td>230868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230971</th>\n",
       "      <td>230972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230972</th>\n",
       "      <td>230973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230973</th>\n",
       "      <td>230974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        treeID1  sp_0  sp_1  sp_2  sp_3  sp_4  sp_5  sp_6   gx         gy  \\\n",
       "8223       8224     0     0     0     0     0     0     1  1.6  24.700001   \n",
       "230867   230868     0     0     0     0     0     1     0  2.8  20.400000   \n",
       "230971   230972     0     0     0     0     0     1     1  0.3  24.100000   \n",
       "230972   230973     0     0     0     0     1     0     0  0.2  24.600000   \n",
       "230973   230974     0     0     0     0     1     0     1  0.8  24.700001   \n",
       "\n",
       "         dbh1  \n",
       "8223    294.0  \n",
       "230867    NaN  \n",
       "230971   15.0  \n",
       "230972   25.0  \n",
       "230973   15.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder= ce.BinaryEncoder(cols=['sp'],return_df=True)\n",
    "data_encoded=encoder.fit_transform(quad1_t1)\n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "species_list = []\n",
    "#df.loc[df['A'] > 2, 'B'] \n",
    "#print (range(len(quad1_t1)))\n",
    "for i in quad1_t1.index:\n",
    "    current = quad1_t1['sp'][i] \n",
    "    #print (current)\n",
    "    if current not in species_list:\n",
    "            species_list.append(current)\n",
    "    quad1_t1['sp'][i]  = species_list.index(current)\n",
    "\n",
    "print (len(species_list))\n",
    "#quad1_t1.head(30)\n",
    "#print(species_list)\n",
    "#quad1_t1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quad1_t1.head(30)\n",
    "#print(species_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO FIX SO THAT I DONT GET THE ERRORS ABOVE! Tried to use df.loc[] but ran into many errors. Also note above that the indices are one less than the tree ID - why is that??\n",
    "\n",
    "https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([quad1_t1, expected_labels], axis=1)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_combined_clean = df_combined.dropna()\n",
    "\n",
    "# Separate the cleaned DataFrame and labels\n",
    "df_clean = df_combined_clean[quad1_t1.columns]\n",
    "labels_clean = df_combined_clean[expected_labels.columns]\n",
    "#df_combined_clean.head()\n",
    "#df_clean.head()\n",
    "#labels_clean.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and validation sets. Here, there's a 70/30 split. Can use scikit-learn's algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert both from above (no null) to numpy arrays\n",
    "quad1_t1 = df_clean.to_numpy()\n",
    "expected_labels = labels_clean.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad1_t1 = quad1_t1.astype(np.float32)\n",
    "expected_labels = expected_labels.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "n, d = quad1_t1.shape\n",
    "#cutoff = int(np.ceil(0.7 * n))\n",
    "# indices of training samples\n",
    "#xTr = quad1_t1[:cutoff,:]\n",
    "#yTr = expected_labels[:cutoff]\n",
    "# indices of testing samples\n",
    "#xTv = quad1_t1[cutoff:,:]\n",
    "#yTv = expected_labels[cutoff:]\n",
    "\n",
    "# above was a way to compute it by hand, but instead can use sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(quad1_t1, expected_labels, test_size=0.3)\n",
    "print (X_train.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT STEPS:\n",
    "1) find the distance between a focal tree and each of its neighbors (sort).\n",
    "2) pick the 50 closest neighbors.\n",
    "3) create a matrix with 150 dimensions:\n",
    "    FOR EACH OF 50 TREES:\n",
    "    distance to the neighbor\n",
    "    species of neighbor\n",
    "    dbh of neighbor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# first convert to numpy arrays\n",
    "#X_train = X_train.to_numpy()\n",
    "#X_test = X_test.to_numpy()\n",
    "#y_train = y_train.to_numpy()\n",
    "#y_test = y_test.to_numpy()\n",
    "\n",
    "#print(type(X_train))\n",
    "\n",
    "# then convert those numpy arrays to tensors\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "#having some errors here, but will be fairly easy to debug I think"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try using sklearn decision tree regressor on just this simple data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train[:,1:], y_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers = X_test[:, 0]  \n",
    "predictions = tree.predict(X_test[:,1:5])\n",
    "predictions_matrix = np.column_stack((identifiers, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.131146793959548\n",
      "0.2953645998958543\n"
     ]
    }
   ],
   "source": [
    "error1 = sklearn.metrics.mean_squared_error(y_test[:,1], predictions)\n",
    "print (np.sqrt(error1))\n",
    "print (np.sqrt(error1)/np.mean(predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done that basic part, let's try some other approaches. First, let's sort by distance. To do this, we'll use sklearn's euclidean distance portion. For the first tree in our dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: organize the data (150). \n",
    "\n",
    "Keep some regularization.\n",
    "\n",
    "Change the model structure so that it includes physical processes that we know.\n",
    "\n",
    "Distance as pseudo-time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ea42a2acbac2542a5ba28118d5ac45aa30cdd1086d6bdd4fc2eb17ce0fd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
