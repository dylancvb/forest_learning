{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhood Growth Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import r2_score\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as mpl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEED TO CREATE A FRAMEWORK TO STANDARDIZE HOW MANY COLUMNS THE ENCODING NEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_640/2288554603.py:2: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_640/2288554603.py:3: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1995.csv\")\n"
     ]
    }
   ],
   "source": [
    "# load all data\n",
    "raw_data_t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "raw_data_t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1995.csv\")\n",
    "\n",
    "# load the first quadrat that we will be working with\n",
    "quad1_t1 = raw_data_t1.loc[raw_data_t1['quadrat']<=50]\n",
    "quad1_t2 = raw_data_t2.loc[raw_data_t2['quadrat']<=50]\n",
    "\n",
    "# we only care about the tree IDs and DBHs of quad1_t2\n",
    "expected_labels = quad1_t2[['treeID', 'dbh']]\n",
    "expected_labels = expected_labels.rename(columns={\"dbh\": \"dbh2\", \"treeID\": \"treeID2\"})\n",
    "\n",
    "#quad1_t1.head()\n",
    "# simplify the data to have less features\n",
    "quad1_t1 = quad1_t1[['treeID', 'sp', 'gx', 'gy', 'dbh']]\n",
    "quad1_t1 = quad1_t1.rename(columns={\"dbh\": \"dbh1\", \"treeID\":\"treeID1\"})\n",
    "\n",
    "encoder= ce.BinaryEncoder(cols=['sp'],return_df=True)\n",
    "quad1_t1 = encoder.fit_transform(quad1_t1)\n",
    "df_combined = pd.concat([quad1_t1, expected_labels], axis=1)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_combined_clean = df_combined.dropna()\n",
    "\n",
    "# round each dbh to the nearest 5!!\n",
    "# featurest1[:,10] = np.around(featurest1[:,10]/5)* 5\n",
    "\n",
    "# Separate the cleaned DataFrame and labels\n",
    "df_clean = df_combined_clean[quad1_t1.columns]\n",
    "labels_clean = df_combined_clean[expected_labels.columns]\n",
    "\n",
    "quad1_t1 = df_clean.to_numpy()\n",
    "expected_labels = labels_clean.to_numpy()\n",
    "\n",
    "quad1_t1 = quad1_t1.astype(np.float32)\n",
    "expected_labels = expected_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY COLS TO ENCODE SPECIES?\n",
    "a = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = quad1_t1[:,0]\n",
    "# X WOULD BE a +1, y would be a+2\n",
    "x_coordinates = quad1_t1[:, a+1]  \n",
    "y_coordinates = quad1_t1[:, a+2]\n",
    "coord_matrix = np.column_stack((x_coordinates, y_coordinates))\n",
    "spatial_tree = sp.spatial.KDTree(coord_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would be a below\n",
    "nn_dist_matrix2 = np.zeros((len(coord_matrix),6))\n",
    "nn_ind_matrix2 = np.zeros((len(coord_matrix),6))\n",
    "nn_feats = np.column_stack((quad1_t1[:, 0:a+1], quad1_t1[:,a+3]))\n",
    "feats_matrix = np.zeros((len(coord_matrix),(6*(a+2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE AS OF JULY 6 - THIS WORKS!!!!!!!!\n",
    "for i, tree in enumerate(coord_matrix):\n",
    "    dist2, ind2 = spatial_tree.query(tree, k=6)\n",
    "    nn_ind_matrix2[i] = ids[ind2]\n",
    "    nn_dist_matrix2[i]= dist2\n",
    "\n",
    "    nn_row = nn_feats[i].reshape(1,a+2)\n",
    "    inc = 0\n",
    "    for j in nn_ind_matrix2[i][1:]:\n",
    "        row_ind = np.where(quad1_t1[:,0] == j)\n",
    "\n",
    "        real_row = (quad1_t1[row_ind])\n",
    "        distance = dist2[1:][inc].reshape(1,1)\n",
    "        dbh = real_row[:,a+3].reshape(1,1)\n",
    "        nn_row = np.hstack((nn_row, distance, real_row[:,1:a+1],dbh))\n",
    "        inc += 1\n",
    "    \n",
    "    feats_matrix[i] = nn_row\n",
    "    \n",
    "nn_ind_matrix2 = nn_ind_matrix2[:,1:]\n",
    "nn_dist_matrix2 = nn_dist_matrix2[:,1:]\n",
    "# remove the columns with the focal tree's OWN distance and IDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the labels so that they show GROWTH, not future DBH - better for readability of loss\n",
    "expected_labels[:,1] = expected_labels[:,1] - quad1_t1[:,a+3]\n",
    "expected_labels = np.where (expected_labels<0, 0, expected_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats_matrix, expected_labels, test_size=0.3)\n",
    "\n",
    "feats = X_train[:,1:]\n",
    "labels = y_train[:,1]\n",
    "\n",
    "test_ids = X_test[:,0]\n",
    "test_feats = X_test[:,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKLearn's Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.167602224639062\n",
      "0.04647977121182889\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_depth=6, n_estimators=100)\n",
    "rf.fit(feats,labels)\n",
    "\n",
    "preds = rf.predict(test_feats)\n",
    "preds_matrix = np.column_stack((test_ids, preds))\n",
    "\n",
    "error1 = sklearn.metrics.mean_squared_error(y_test[:,1], preds)\n",
    "print (np.sqrt(error1))\n",
    "error1a = r2_score(y_test[:,1], preds)\n",
    "print (error1a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.23569\n",
      "0.034817317400235304\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBRegressor()\n",
    "xgb_tree.fit(feats,labels)\n",
    "preds2 = xgb_tree.predict(test_feats)\n",
    "predictions_matrix = np.column_stack((test_ids, preds2))\n",
    "error2 = sklearn.metrics.mean_squared_error(y_test[:,1], preds2)\n",
    "print (np.sqrt(error2))\n",
    "error2a = r2_score (y_test[:,1], preds2)\n",
    "print (error2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.1002466   -5.63812705 -25.44887027  -8.47231649 -19.06206055]\n",
      "[ 0.01772266  0.14698852 -5.04979049 -0.37882216  0.02933778]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5)\n",
    "scores = cross_validate(rf, quad1_t1[:,1:],expected_labels[:,1], scoring=('neg_root_mean_squared_error','r2'), cv=cv)\n",
    "\n",
    "print (scores['test_neg_root_mean_squared_error'])\n",
    "print (scores['test_r2'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomization attempts below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 20 random sequences of 1 to 5 - COMPLETE\n",
    "rng = np.random.default_rng()\n",
    "matrix_order = np.zeros((20,5))\n",
    "\n",
    "shuffle_this = np.array([0, 1, 2, 3, 4])\n",
    "for i in range(20):\n",
    "  current_row = rng.permutation(shuffle_this)\n",
    "  matrix_order[i] = current_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dist_matrix3 = np.zeros((len(coord_matrix),6))\n",
    "nn_ind_matrix3 = np.zeros((len(coord_matrix),6))\n",
    "nn_feats2 = np.column_stack((quad1_t1[:, 0:a+1], quad1_t1[:,a+3]))\n",
    "#feats_matrix = np.zeros((len(coord_matrix),54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with feats_matrix above. Then create similar matrices for each of the above\n",
    "feats_matrix_big = feats_matrix.copy()\n",
    "# feats matrix small is miossing focal dbh\n",
    "\n",
    "# of columns should be a*6\n",
    "\n",
    "zer_indices = range(a+2,2*a+4)\n",
    "one_indices = range (2*a+4,3*a+6)\n",
    "two_indices = range (3*a+6,4*a+8)\n",
    "three_indices = range (4*a+8,5*a+10)\n",
    "four_indices = range (5*a+10,6*a+12)\n",
    "\n",
    "# the long number passing into range is ust n=20 here, but this would make it less hard-coded in\n",
    "for i in range(np.shape(matrix_order)[0]):\n",
    "    # loop through each permutation.\n",
    "    feats_matrix_small = feats_matrix.copy()\n",
    "    perm_indices = [range(a+2)]\n",
    "    current_perm = matrix_order[i]\n",
    "    for x in current_perm:\n",
    "        if x == 0:\n",
    "          perm_indices.append(zer_indices)\n",
    "        elif x == 1:\n",
    "           perm_indices.append(one_indices)\n",
    "        elif x == 2:\n",
    "           perm_indices.append(two_indices)\n",
    "        elif x == 3:\n",
    "           perm_indices.append(three_indices)\n",
    "        elif x == 4:\n",
    "           perm_indices.append(four_indices)\n",
    "    flattened = []\n",
    "    for sublist in perm_indices:\n",
    "       for item in sublist:\n",
    "          flattened.append(item)\n",
    "    feats_matrix_small = feats_matrix_small[:,flattened]\n",
    "    feats_matrix_big = np.vstack((feats_matrix_big,feats_matrix_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corresponding y labels - THIS WORKS! # of rows = 138x20\n",
    "expected_labels2 = expected_labels.copy()\n",
    "for i in range(20):\n",
    "    expected_labels2 = np.vstack((expected_labels2, expected_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([37.01697111, 43.03562021, 40.67548513, 37.09245896, 43.14177704]), 'score_time': array([0.11007786, 0.12534285, 0.11203003, 0.11108303, 0.11647511]), 'test_neg_root_mean_squared_error': array([-7.73608462, -8.02349681, -8.00131782, -7.81267053, -8.49282321]), 'test_r2': array([0.56001399, 0.5160398 , 0.52980099, 0.54312353, 0.51666179])}\n"
     ]
    }
   ],
   "source": [
    "cv2 = KFold(n_splits=5)\n",
    "cv_rf2 = RandomForestRegressor(max_depth=8)\n",
    "\n",
    "scores = cross_validate(cv_rf2, feats_matrix_big[:,1:], expected_labels2[:,1], scoring=('neg_root_mean_squared_error','r2'), cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create framework to print anything: (incorporated from diagnostics file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = encoder.inverse_transform(quad1_t1)\n",
    "sp_list = names.sp.unique()\n",
    "sp_freq = names.sp.value_counts(sort=True).index.tolist()\n",
    "sp_num = sp_list.shape[0]\n",
    "sp_mat = np.hstack((np.atleast_2d(sp_list).transpose(), (np.zeros((sp_num, a)))))\n",
    "\n",
    "all_dbhs = np.arange(10,501,5).transpose()\n",
    "all_dbhs_big = np.arange(10,501,5).transpose()\n",
    "list_of_all_sp = []\n",
    "\n",
    "for i in range(sp_num):\n",
    "    # 1) look at initial dataset and find the tree with that ID, then find its encoding\n",
    "    # find tree ID of one instance of a species\n",
    "    tree_id = names[names.sp == sp_freq[i]].treeID1\n",
    "    one_tree_id = tree_id.iloc[0]\n",
    "    encoding = feats_matrix_big[feats_matrix_big[:,0]==one_tree_id][0,1:a+1]\n",
    "\n",
    "    sp_label = np.atleast_2d(encoding)\n",
    "    sp_repeated = np.repeat(sp_label,99,axis=0)\n",
    "    sp_i = np.column_stack((sp_repeated,all_dbhs))\n",
    "    all_dbhs_big = np.vstack((all_dbhs_big, all_dbhs))\n",
    "    list_of_all_sp.append(sp_i)\n",
    "\n",
    "one_big_array = np.vstack(list_of_all_sp)\n",
    "all_dbhs_big = (all_dbhs_big.flatten())[:a*3234] # can be represented by a*3234?\n",
    "\n",
    "list_of_all_preds = []\n",
    "for sp in list_of_all_sp:\n",
    "    # adjust as if it had all zero neighbors\n",
    "    sp_adjusted = np.column_stack((sp,np.zeros((99,5*(a+2)))))\n",
    "    preds = rf.predict(sp_adjusted)\n",
    "    list_of_all_preds.append(preds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, compare the model with 0 neighbors to the intrinsic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data as if each focal tree had no neighbors, but the actual trees are from our data\n",
    "\n",
    "comparison = np.hstack((nn_feats,np.zeros((np.shape(nn_feats)[0],a*5))))\n",
    "feats_matrix_big2 = comparison.copy()\n",
    "for i in range(np.shape(matrix_order)[0]):\n",
    "    # loop through each permutation.\n",
    "    feats_matrix_big2 = np.vstack((feats_matrix_big2,comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(cv_rf2, feats_matrix_big2[:,1:], expected_labels2[:,1], scoring=('neg_root_mean_squared_error','r2'), cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([5.19270301, 5.93953824, 5.28836203, 4.73146391, 4.69043088]), 'score_time': array([0.11352801, 0.11210704, 0.11695671, 0.10414004, 0.11284518]), 'test_neg_root_mean_squared_error': array([-7.52899542, -7.48939002, -7.61969456, -7.54150771, -7.89951323]), 'test_r2': array([0.5832549 , 0.57832761, 0.5735837 , 0.57428777, 0.58183505])}\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "# These are the r2 scores for cross validation for a model trained on 50 quadrats.\n",
    "# It is only taking into account dbh and species of the FOCAL tree\n",
    "# But it is organized in the format of the neighborhood model.\n",
    "# Thus, we can compare it to the intrinsic model (in diagnostics2). \n",
    "# (Though the diagnostics model was trained on ALL data)\n",
    "\n",
    "# Indeed, it is odd that the average r2 here is about 0.57. On the other hand, the r2 \n",
    "# for the intrinsic model is only about 0.14 on average. They should be more comparable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ea42a2acbac2542a5ba28118d5ac45aa30cdd1086d6bdd4fc2eb17ce0fd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
