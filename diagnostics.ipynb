{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting diagnostic information on species growth!**\n",
    "Method: \n",
    "1) TRAIN the model on all data from the census.\n",
    "2) For each species present, create a dataset where all the trees are of that one species and every DBH from 10 to 500 is represented.\n",
    "3) Use this dataset as a test set.\n",
    "4) Instead of calculating a loss function, plot the output as a function of the DBH input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as mpl\n",
    "import data_processing\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to use data processing script! - DO NOT RUN UNTIL DEBUGGED!!\n",
    "importlib.reload(data_processing)\n",
    "paths = (\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\",\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "feats, labels, test_ids, test_feats = data_processing.clean(paths, num_quads=400)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below instead of the preprocessing file for now!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_37834/1666651563.py:2: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_37834/1666651563.py:3: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n"
     ]
    }
   ],
   "source": [
    "# load all data, using just the 1985 to 1990 data to train for now\n",
    "t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
    "t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "\n",
    "# simplify columns and column names\n",
    "expected_labels = t2[['treeID', 'dbh']]\n",
    "expected_labels = expected_labels.rename(columns={\"dbh\": \"dbh2\", \"treeID\": \"treeID2\"})\n",
    "featurest1 = t1[['treeID', 'sp', 'dbh']]\n",
    "featurest1 = featurest1.rename(columns={\"dbh\": \"dbh1\", \"treeID\":\"treeID1\"})\n",
    "\n",
    "# encode the species into binary features and drop rows with any NaN values\n",
    "encoder= ce.BinaryEncoder(cols=['sp'],return_df=True)\n",
    "featurest1 = encoder.fit_transform(featurest1)\n",
    "\n",
    "df_combined = pd.concat([featurest1, expected_labels], axis=1)\n",
    "df_combined_clean = df_combined.dropna()\n",
    "\n",
    "# split back up and convert the dataframes to numpy arrays\n",
    "df_clean = df_combined_clean[featurest1.columns]\n",
    "labels_clean = df_combined_clean[expected_labels.columns]\n",
    "\n",
    "featurest1 = df_clean.to_numpy()\n",
    "expected_labels = labels_clean.to_numpy()\n",
    "\n",
    "featurest1 = featurest1.astype(np.float32)\n",
    "expected_labels = expected_labels.astype(np.float32)\n",
    "\n",
    "# ensure that there is only positive growth, represented by CHANGE (not total dbh)\n",
    "expected_labels[:,1] = expected_labels[:,1] - featurest1[:,10]\n",
    "expected_labels = np.where (expected_labels<0, 0, expected_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is processed, train a random forest on ALL of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained on ALL of the data from 1985 to 1990\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(featurest1[:,1:], expected_labels[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor()\n",
    "xg.fit(featurest1[:,1:], expected_labels[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: potentially use skorch to use some GPU features with sklearn features.\n",
    "\n",
    "Random forest took one minute 30 seconds.\n",
    "\n",
    "XG took only 19.5 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "all_dbhs = np.arange(10,501).transpose()\n",
    "sp_label = np.atleast_2d(featurest1[0,1:10])\n",
    "sp_repeated = np.repeat(sp_label,491,axis=0)\n",
    "print (sp_repeated)\n",
    "sp_1 = np.column_stack((sp_repeated,all_dbhs))\n",
    "\n",
    "predictions_sp1 = rf.predict(sp_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: attempting to create the framework for each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof of concept for first species!\n",
    "all_dbhs = np.arange(10,501).transpose()\n",
    "sp_label = np.atleast_2d(featurest1[0,1:10])\n",
    "sp_repeated = np.repeat(sp_label,491,axis=0)\n",
    "sp_1 = np.column_stack((sp_repeated,all_dbhs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = encoder.inverse_transform(featurest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_list = names.sp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_num = sp_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n",
      "i work now!\n"
     ]
    }
   ],
   "source": [
    "sp_mat = np.hstack((np.atleast_2d(sp_list).transpose(), (np.zeros((sp_num, 9)))))\n",
    "for i in range(sp_num):\n",
    "    # for each, need to just find the encoding! and append it here!\n",
    "    # two ways: \n",
    "    # 1) look at initial dataset and find the tree with that ID, then find its encoding\n",
    "    # 2) run through encoder again\n",
    "    # method 1 used below\n",
    "    print (\"i work now!\")\n",
    "    #  id of one tree with that species is provided by names\n",
    "    #tree_id = np.where(names[:,0] == sp_list[i,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create curve for the most abundant species. train once with all of the data.\n",
    "\n",
    "treat each consecutive census as a batch\n",
    "\n",
    "2000=2005\n",
    "\n",
    "assume they have no memory. assume all the growth can be predicted from the current status."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considering previous time series is not as simple as you think. time difference. some trees can be missing. one way to start if including multiple censuses\n",
    "\n",
    "include a feature of the census interval identifier\n",
    "\"maybe 2005 to 2010 has much more rain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ea42a2acbac2542a5ba28118d5ac45aa30cdd1086d6bdd4fc2eb17ce0fd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
