{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we define death? ID is part of one census and not the next? IDEA: where in t2, DFstatus==dead OR agb==0\n",
    "\n",
    "only 335 are labeled \"dead\" whereas 3,203 have an agb of 0 - which should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import r2_score\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as mpl\n",
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_24157/2191185153.py:1: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
      "/var/folders/zf/kbwgwbdd4gjfhdxc9cnw8qgm0000gn/T/ipykernel_24157/2191185153.py:2: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n"
     ]
    }
   ],
   "source": [
    "t1 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1985.csv\")\n",
    "t2 = pd.read_csv(\"/Users/dylanvanbramer/indresearch/xu/deep_learning/bci_census/bci_1990.csv\")\n",
    "\n",
    "\n",
    "# load the first quadrat that we will be working with\n",
    "quad1_t1 = t1.loc[t1['quadrat']<=50]\n",
    "quad1_t2 = t2.loc[t2['quadrat']<=50]\n",
    "\n",
    "# we only care about the tree IDs and DBHs of quad1_t2\n",
    "expected_labels = quad1_t2[['treeID', 'agb', 'DFstatus' ]]\n",
    "expected_labels = expected_labels.rename(columns={\"treeID\": \"treeID2\"})\n",
    "\n",
    "#quad1_t1.head()\n",
    "# simplify the data to have less features\n",
    "quad1_t1 = quad1_t1[['treeID', 'sp', 'gx', 'gy', 'dbh']]\n",
    "quad1_t1 = quad1_t1.rename(columns={\"dbh\": \"dbh1\", \"treeID\":\"treeID1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION PROBLEM - USING SAME DATA STRUCTURE AS NEIGHBORHOOD - trying to determine whether it dies or not in t2!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change all DEAD to 0, change all ALIVE to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels.loc[expected_labels['DFstatus'] == 'dead', 'DFstatus'] = 0\n",
    "expected_labels.loc[expected_labels['DFstatus'] == 'missing', 'DFstatus'] = 0\n",
    "expected_labels.loc[expected_labels['DFstatus'] == 'alive', 'DFstatus'] = 1\n",
    "\n",
    "# also change any nonzero agb to 1 - more options later on for what we want to select as features\n",
    "expected_labels.loc[expected_labels['agb'] > 0, 'agb'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= ce.BinaryEncoder(cols=['sp'],return_df=True)\n",
    "quad1_t1 = encoder.fit_transform(quad1_t1)\n",
    "df_combined = pd.concat([quad1_t1, expected_labels], axis=1)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_combined_clean = df_combined.dropna()\n",
    "\n",
    "# Separate the cleaned DataFrame and labels\n",
    "df_clean = df_combined_clean[quad1_t1.columns]\n",
    "labels_clean = df_combined_clean[expected_labels.columns]\n",
    "\n",
    "quad1_t1 = df_clean.to_numpy()\n",
    "expected_labels = labels_clean.to_numpy()\n",
    "\n",
    "quad1_t1 = quad1_t1.astype(np.float32)\n",
    "expected_labels = expected_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY COLS TO ENCODE SPECIES?\n",
    "a = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = quad1_t1[:,0]\n",
    "# X WOULD BE a +1, y would be a+2\n",
    "x_coordinates = quad1_t1[:, a+1]  \n",
    "y_coordinates = quad1_t1[:, a+2]\n",
    "coord_matrix = np.column_stack((x_coordinates, y_coordinates))\n",
    "spatial_tree = sp.spatial.KDTree(coord_matrix)\n",
    "\n",
    "nn_dist_matrix2 = np.zeros((len(coord_matrix),6))\n",
    "nn_ind_matrix2 = np.zeros((len(coord_matrix),6))\n",
    "nn_feats = np.column_stack((quad1_t1[:, 0:a+1], quad1_t1[:,a+3]))\n",
    "feats_matrix = np.zeros((len(coord_matrix),(6*(a+2))))\n",
    "\n",
    "for i, tree in enumerate(coord_matrix):\n",
    "    dist2, ind2 = spatial_tree.query(tree, k=6)\n",
    "    nn_ind_matrix2[i] = ids[ind2]\n",
    "    nn_dist_matrix2[i]= dist2\n",
    "\n",
    "    nn_row = nn_feats[i].reshape(1,a+2)\n",
    "    inc = 0\n",
    "    for j in nn_ind_matrix2[i][1:]:\n",
    "        row_ind = np.where(quad1_t1[:,0] == j)\n",
    "\n",
    "        real_row = (quad1_t1[row_ind])\n",
    "        distance = dist2[1:][inc].reshape(1,1)\n",
    "        dbh = real_row[:,a+3].reshape(1,1)\n",
    "        nn_row = np.hstack((nn_row, distance, real_row[:,1:a+1],dbh))\n",
    "        inc += 1\n",
    "    \n",
    "    feats_matrix[i] = nn_row\n",
    "    \n",
    "nn_ind_matrix2 = nn_ind_matrix2[:,1:]\n",
    "nn_dist_matrix2 = nn_dist_matrix2[:,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomization below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "matrix_order = np.zeros((20,5))\n",
    "\n",
    "shuffle_this = np.array([0, 1, 2, 3, 4])\n",
    "for i in range(20):\n",
    "  current_row = rng.permutation(shuffle_this)\n",
    "  matrix_order[i] = current_row\n",
    "\n",
    "\n",
    "nn_dist_matrix3 = np.zeros((len(coord_matrix),6))\n",
    "nn_ind_matrix3 = np.zeros((len(coord_matrix),6))\n",
    "nn_feats2 = np.column_stack((quad1_t1[:, 0:a+1], quad1_t1[:,a+3]))\n",
    "\n",
    "# Start with feats_matrix above. Then create similar matrices for each of the above\n",
    "feats_matrix_big = feats_matrix.copy()\n",
    "# feats matrix small is miossing focal dbh\n",
    "\n",
    "# of columns should be a*6\n",
    "\n",
    "zer_indices = range(a+2,2*a+4)\n",
    "one_indices = range (2*a+4,3*a+6)\n",
    "two_indices = range (3*a+6,4*a+8)\n",
    "three_indices = range (4*a+8,5*a+10)\n",
    "four_indices = range (5*a+10,6*a+12)\n",
    "\n",
    "# the long number passing into range is ust n=20 here, but this would make it less hard-coded in\n",
    "for i in range(np.shape(matrix_order)[0]):\n",
    "    # loop through each permutation.\n",
    "    feats_matrix_small = feats_matrix.copy()\n",
    "    perm_indices = [range(a+2)]\n",
    "    current_perm = matrix_order[i]\n",
    "    for x in current_perm:\n",
    "        if x == 0:\n",
    "          perm_indices.append(zer_indices)\n",
    "        elif x == 1:\n",
    "           perm_indices.append(one_indices)\n",
    "        elif x == 2:\n",
    "           perm_indices.append(two_indices)\n",
    "        elif x == 3:\n",
    "           perm_indices.append(three_indices)\n",
    "        elif x == 4:\n",
    "           perm_indices.append(four_indices)\n",
    "    flattened = []\n",
    "    for sublist in perm_indices:\n",
    "       for item in sublist:\n",
    "          flattened.append(item)\n",
    "    feats_matrix_small = feats_matrix_small[:,flattened]\n",
    "    feats_matrix_big = np.vstack((feats_matrix_big,feats_matrix_small))\n",
    "\n",
    "expected_labels2 = expected_labels.copy()\n",
    "for i in range(20):\n",
    "    expected_labels2 = np.vstack((expected_labels2, expected_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats_matrix_big, expected_labels2, test_size=0.3)\n",
    "\n",
    "feats = X_train[:,1:]\n",
    "labels = y_train[:,2]\n",
    "\n",
    "test_ids = X_test[:,0]\n",
    "test_feats = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30453538675148867\n",
      "0.1978992284021559\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBClassifier()\n",
    "xgb_tree.fit(feats,labels)\n",
    "preds2 = xgb_tree.predict(test_feats)\n",
    "predictions_matrix = np.column_stack((test_ids, preds2))\n",
    "error2 = sklearn.metrics.mean_squared_error(y_test[:,2], preds2)\n",
    "print (np.sqrt(error2))\n",
    "error2a = r2_score (y_test[:,2], preds2)\n",
    "print (error2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([10.27572203,  8.62734485,  8.465734  ,  8.25633192,  8.4396143 ]),\n",
       " 'score_time': array([0.02098989, 0.01895499, 0.01958394, 0.02057409, 0.01789188]),\n",
       " 'test_neg_root_mean_squared_error': array([-0.27738458, -0.3036631 , -0.29435542, -0.2941864 , -0.3016163 ]),\n",
       " 'test_r2': array([0.32565988, 0.19027595, 0.23672422, 0.24005913, 0.21082811])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=5)\n",
    "cross_validate(xgb_tree, feats_matrix_big[:,1:], expected_labels2[:,2], scoring=('neg_root_mean_squared_error','r2'), cv=cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost seems to work much better here! Things online suggest that this might be the case\" without boosting, it will just predict majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36527547\n",
      "-0.15396979081506057\n",
      "{'fit_time': array([7.50488877, 7.34737396, 7.10704303, 6.76504493, 6.78624821]), 'score_time': array([0.17878914, 0.19966912, 0.17845511, 0.18137503, 0.17780185]), 'test_neg_root_mean_squared_error': array([-0.36242768, -0.36201575, -0.36133716, -0.36202475, -0.36462584]), 'test_r2': array([-0.15121672, -0.1508214 , -0.1501716 , -0.15083   , -0.15333869])}\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=8, n_estimators=100)\n",
    "rf2.fit(feats,labels)\n",
    "\n",
    "preds = rf2.predict(test_feats)\n",
    "preds_matrix = np.column_stack((test_ids, preds))\n",
    "\n",
    "error1 = sklearn.metrics.mean_squared_error(y_test[:,2], preds)\n",
    "print (np.sqrt(error1))\n",
    "error1a = r2_score(y_test[:,2], preds)\n",
    "print (error1a)\n",
    "\n",
    "\n",
    "cv_rf = RandomForestClassifier (max_depth=8)\n",
    "\n",
    "scores = cross_validate(cv_rf, feats_matrix_big[:,1:], expected_labels2[:,2], scoring=('neg_root_mean_squared_error','r2'), cv=cv)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ea42a2acbac2542a5ba28118d5ac45aa30cdd1086d6bdd4fc2eb17ce0fd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
